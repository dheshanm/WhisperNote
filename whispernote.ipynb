{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyannote.audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "from pyannote.audio.pipelines.utils.hook import ProgressHook\n",
    "\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "key_path = os.path.join(Path.home(), \".keys\", \"huggingface.key\")\n",
    "key = open(key_path, \"r\").read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline.from_pretrained('pyannote/speaker-diarization', use_auth_token=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = '/data/sbdp/PHOENIX/PROTECTED/CAMI/CAMI221/onsite_interview/processed/CAMI-CAMI221-onsiteInterview_audio_webcam-day002_9.mp3'\n",
    "\n",
    "waveform, sample_rate = torchaudio.load(audio_path)\n",
    "with ProgressHook() as hook:\n",
    "    diarization = pipeline({\"waveform\": waveform, \"sample_rate\": sample_rate}, hook=hook, num_speakers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = []\n",
    "cumulative_durations = []\n",
    "\n",
    "for segment, _, label in diarization.itertracks(yield_label=True):\n",
    "    speaker = label\n",
    "    start, end, duration = segment.start, segment.end, segment.duration\n",
    "\n",
    "    if speaker not in speakers:\n",
    "        speakers.append(speaker)\n",
    "        cumulative_durations.append(0)\n",
    "\n",
    "    speaker_index = speakers.index(speaker)\n",
    "    cumulative_durations[speaker_index] += duration\n",
    "    \n",
    "for speaker in speakers:\n",
    "    speaker_index = speakers.index(speaker)\n",
    "    print(f\"{speaker} spoke for {cumulative_durations[speaker_index]} seconds.\")\n",
    "\n",
    "# interviewer speaks less than interviewee\n",
    "interviewer_index = cumulative_durations.index(min(cumulative_durations))\n",
    "interviewee_index = cumulative_durations.index(max(cumulative_durations))\n",
    "\n",
    "print(f\"Interviewer: {speakers[interviewer_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"diarization.txt\", \"w\") as text_file:\n",
    "    for segment, _, label in diarization.itertracks(yield_label=True):\n",
    "        speaker = label\n",
    "        start, end, duration = segment.start, segment.end, segment.duration\n",
    "        start_ms = int(start * 1000)\n",
    "        end_ms = int(end * 1000)\n",
    "\n",
    "        if speaker == speakers[interviewer_index]:\n",
    "            text_file.write(f\"{start_ms},{end_ms},Interviewer\\n\")\n",
    "\n",
    "        if speaker == speakers[interviewee_index]:\n",
    "            text_file.write(f\"{start_ms},{end_ms},Participant\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = '/data/sbdp/PHOENIX/PROTECTED/CAMI/CAMI221/onsite_interview/processed/CAMI-CAMI221-onsiteInterview_audio_webcam-day002_9.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transcribe(audio_path, verbose=True, word_timestamps=True, language=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "segments = result['segments']\n",
    "for segment in segments:\n",
    "    start, end, transcript = int(segment['start']), int(segment['end']), segment['text']\n",
    "\n",
    "    # words = segment['words']\n",
    "    # for word in words:\n",
    "    #     start, end, word = (word['start']), (word['end']), word['word']\n",
    "    #     start_ms = int(start * 1000)\n",
    "    #     end_ms = int(end * 1000)\n",
    "    #     print(f\"{start} - {end}: {word}\")\n",
    "\n",
    "    start_ms = int(start * 1000)\n",
    "    end_ms = int(end * 1000)\n",
    "    print(f\"{start} - {end}: {transcript}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transcript.txt\", \"w\") as text_file:\n",
    "    for segment in segments:\n",
    "        start, end, transcript = int(segment['start']), int(segment['end']), segment['text']\n",
    "\n",
    "        words = segment['words']\n",
    "        for word in words:\n",
    "            start, end, word = (word['start']), (word['end']), word['word']\n",
    "            start_ms = int(start * 1000)\n",
    "            end_ms = int(end * 1000)\n",
    "            text_file.write(f\"{start_ms},{end_ms},{word}\\n\")\n",
    "\n",
    "        # start_ms = int(start * 1000)\n",
    "        # end_ms = int(end * 1000)\n",
    "\n",
    "        # text_file.write(f\"{start_ms},{end_ms},{transcript}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ms_to_srt(ms: float) -> str:\n",
    "    # Convert milliseconds to seconds\n",
    "    s = ms / 1000\n",
    "    # Extract hours, minutes and seconds\n",
    "    h = int(s // 3600)\n",
    "    m = int((s % 3600) // 60)\n",
    "    s = int(s % 60)\n",
    "    # Extract milliseconds\n",
    "    mil = int((ms % 1000))\n",
    "    # Format the timestamp as HH:MM:SS,MIL\n",
    "    return f\"{h:02d}:{m:02d}:{s:02d},{mil:03d}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "\n",
    "\n",
    "class SubtitleElement:\n",
    "    def __init__(\n",
    "        self,\n",
    "        start_ms: int,\n",
    "        end_ms: int,\n",
    "        text: str,\n",
    "        speaker: str,\n",
    "        index: Optional[int] = None,\n",
    "    ) -> None:\n",
    "        self.index = index\n",
    "        self.start_ms = start_ms\n",
    "        self.end_ms = end_ms\n",
    "        self.text = text.strip()\n",
    "        self.speaker = speaker\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        string_representation = f\"\"\"{self.index}\\n{ms_to_srt(self.start_ms)} --> {ms_to_srt(self.end_ms)}\\n[{self.speaker}]\\n{self.text.strip()}\\n\"\"\"\n",
    "        return string_representation\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return self.__str__()\n",
    "\n",
    "\n",
    "class Subtitles:\n",
    "    def __init__(self) -> None:\n",
    "        self.index = 0\n",
    "        self.elements: List[SubtitleElement] = []\n",
    "\n",
    "    def add_element(self, element: SubtitleElement) -> None:\n",
    "        element.index = self.index\n",
    "        self.index += 1\n",
    "        self.elements.append(element)\n",
    "\n",
    "    def join_adjacent_elements(self):\n",
    "        # If speaker is the same, and the first element doesn't end with a stop symbol, join them\n",
    "        stop_characters = [\".\", \"?\", \"!\"]\n",
    "        max_words_per_line = 7\n",
    "\n",
    "        idx = 0\n",
    "        while idx < len(self.elements) - 1:\n",
    "            element = self.elements[idx]\n",
    "            next_element = self.elements[idx + 1]\n",
    "\n",
    "            if (\n",
    "                element.speaker == next_element.speaker\n",
    "                and element.text[-1] not in stop_characters\n",
    "                and len(element.text.split(\" \")) < max_words_per_line\n",
    "            ):\n",
    "                element.text = element.text.strip() + \" \" + next_element.text.strip()\n",
    "                element.end_ms = next_element.end_ms\n",
    "                self.elements.remove(next_element)\n",
    "            else:\n",
    "                idx += 1\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        string_representation = \"\"\n",
    "        for element in self.elements:\n",
    "            string_representation += str(element) + \"\\n\"\n",
    "        return string_representation\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return self.__str__()\n",
    "    \n",
    "    def to_file(self, path: str) -> None:\n",
    "        with open(path, \"w\") as text_file:\n",
    "            text_file.write(str(self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = open(\"transcript.txt\", \"r\").read().strip()\n",
    "diarization = open(\"diarization.txt\", \"r\").read().strip()\n",
    "\n",
    "transcript = transcript.split(\"\\n\")\n",
    "diarization = diarization.split(\"\\n\")\n",
    "\n",
    "subtitles = Subtitles()\n",
    "\n",
    "for transcript_line in transcript:\n",
    "    transcript_parts = transcript_line.split(\",\")\n",
    "    transcript_start = transcript_parts[0]\n",
    "    transcript_end = transcript_parts[1]\n",
    "    transcript_text = \",\".join(transcript_parts[2:])\n",
    "\n",
    "    transcript_start, transcript_end = int(transcript_start), int(transcript_end)\n",
    "\n",
    "    cumulative_durations = dict()\n",
    "    cumulative_durations[\"Interviewer\"] = 0\n",
    "    cumulative_durations[\"Participant\"] = 0\n",
    "\n",
    "    for diarization_line in diarization:\n",
    "        diarization_start, diarization_end, speaker = diarization_line.split(\",\")\n",
    "        diarization_start, diarization_end = int(diarization_start), int(\n",
    "            diarization_end\n",
    "        )\n",
    "\n",
    "        if diarization_start > transcript_end:\n",
    "            # cumulative_durations[speaker] += transcript_end - transcript_start\n",
    "            break\n",
    "        elif diarization_end < transcript_start:\n",
    "            continue\n",
    "\n",
    "        if diarization_end < transcript_start:\n",
    "            cumulative_durations[speaker] += diarization_end - diarization_start\n",
    "        elif diarization_start > transcript_end:\n",
    "            pass\n",
    "        else:\n",
    "            cumulative_durations[speaker] += transcript_end - max(\n",
    "                diarization_start, transcript_start\n",
    "            )\n",
    "\n",
    "    primary_speaker = max(cumulative_durations, key=cumulative_durations.get)\n",
    "    print(f\"{primary_speaker}: {transcript_text}\")\n",
    "\n",
    "    subtitle_element = SubtitleElement(\n",
    "        start_ms=transcript_start,\n",
    "        end_ms=transcript_end,\n",
    "        text=transcript_text,\n",
    "        speaker=primary_speaker,\n",
    "    )\n",
    "    subtitles.add_element(subtitle_element)\n",
    "\n",
    "    # # convert from ms to srt format (00:00:00,000)\n",
    "    # start = ms_to_srt(transcript_start)\n",
    "    # end = ms_to_srt(transcript_end)\n",
    "\n",
    "    # srt_file.write(f\"{transcript_idx}\\n\")\n",
    "    # srt_file.write(f\"{start} --> {end}\\n\")\n",
    "    # srt_file.write(f\"{primary_speaker}\\n\")\n",
    "    # srt_file.write(f\"{cumulative_durations}\\n\")\n",
    "    # srt_file.write(f\"{transcript_text.strip()}\\n\\n\")\n",
    "\n",
    "    # transcript_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitles.join_adjacent_elements()\n",
    "subtitles.to_file(\"subtitles.srt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = open(\"transcript.txt\", \"r\").read().strip()\n",
    "diarization = open(\"diarization.txt\", \"r\").read().strip()\n",
    "\n",
    "transcript = transcript.split(\"\\n\")\n",
    "diarization = diarization.split(\"\\n\")\n",
    "\n",
    "transcript_idx = 0\n",
    "with open(\"subtitles.srt\", \"w\") as srt_file:\n",
    "    for transcript_line in transcript:\n",
    "        transcript_parts = transcript_line.split(\",\")\n",
    "        transcript_start = transcript_parts[0]\n",
    "        transcript_end = transcript_parts[1]\n",
    "        transcript_text = \",\".join(transcript_parts[2:])\n",
    "\n",
    "        transcript_start, transcript_end = int(transcript_start), int(transcript_end)\n",
    "\n",
    "        cumulative_durations = dict()\n",
    "        cumulative_durations[\"Interviewer\"] = 0\n",
    "        cumulative_durations[\"Participant\"] = 0\n",
    "        \n",
    "        for diarization_line in diarization:\n",
    "            diarization_start, diarization_end, speaker = diarization_line.split(\",\")\n",
    "            diarization_start, diarization_end = int(diarization_start), int(diarization_end)\n",
    "\n",
    "            if diarization_start > transcript_end:\n",
    "                # cumulative_durations[speaker] += transcript_end - transcript_start\n",
    "                break\n",
    "            elif diarization_end < transcript_start:\n",
    "                continue\n",
    "\n",
    "            if diarization_end < transcript_start:\n",
    "                cumulative_durations[speaker] += diarization_end - diarization_start\n",
    "            elif diarization_start > transcript_end:\n",
    "                pass\n",
    "            else:\n",
    "                cumulative_durations[speaker] += transcript_end - max(diarization_start, transcript_start)\n",
    "\n",
    "        primary_speaker = max(cumulative_durations, key=cumulative_durations.get)\n",
    "        print(f\"{primary_speaker}: {transcript_text}\")\n",
    "\n",
    "        # convert from ms to srt format (00:00:00,000)\n",
    "        start = ms_to_srt(transcript_start)\n",
    "        end = ms_to_srt(transcript_end)\n",
    "\n",
    "        srt_file.write(f\"{transcript_idx}\\n\")\n",
    "        srt_file.write(f\"{start} --> {end}\\n\")\n",
    "        srt_file.write(f\"{primary_speaker}\\n\")\n",
    "        srt_file.write(f\"{cumulative_durations}\\n\")\n",
    "        srt_file.write(f\"{transcript_text.strip()}\\n\\n\")\n",
    "\n",
    "        transcript_idx += 1\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
